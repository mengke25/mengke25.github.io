---
layout: post
title: "【Memo】对实证分析的认知，以及如何调整实证结果"
date:   2024-5-25
tags: [Memo]
comments: true

author: mengke25
---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

对于很多硕博生来说，实证分析是最基础的研究方法。本篇博客将分享我对实证分析的一些想法，也会分享我平时调整实证结果的思路。

<!-- more -->

#### 1.对实证分析的理解

个人认为，实证分析是`手段`，而非`目标`。现在很多实证分析做的天花乱坠，颇有“艺术感”，包括曾经我也想在实证方法上追求极致的“艺术感”。但现在我觉得这些方面做得再fancy，也只不过是对结果一种呈现，只不过是为论点提供证据；这和用Raw-data画图寻求证据支持论点没有本质区别。

当然，还有很多人认为，实证分析是一种“把戏”，完全可以通过调整来达到自己想要的结果。这种想法也存在一定问题。因为在不伪造数据的前提下，对现有数据进行挖掘寻求论点，那么数据蕴含的信息（分布、数量关系）就已经决定了实证分析的结果；当然，我们可以通过分组、替换估计方法等方式在一定程度上做出调整，但这些并不会影响变量本身的数量关系。（不过reg monkey就另说了，如果认为，在不讨论变量因果关联、数量关系的前提下，任意调整控制变量来让结果变好，那么ok，这样确实很tricky，我也会认为实证分析是一种“把戏”）

总之，我的意思是，实证分析应该重点关注`通过数据洞察变量之间的数量关系、因果逻辑`，而绝非是`加减变量操作让结果显著`。一篇好的经济学研究最重要的内核理应是选题和理论，识别方法是用来佐证核心观点的方法手段。

#### 2.实证结果不显著怎么办

首先需说明的是，我们不能只盯着系数的显著性，更应重点关注系数的大小。因为系数的大小反映了X与Y的相关程度有多大，或者说X对Y的解释力度有多大。很多时候，我们可能只顾着“数星星”，而忽略了系数数值大小背后的经济学解释。

我们所关注的星星（***），直接受到`系数大小`和`标准误大小`的影响。（$pval=ceof. / se.$​，p值小于10%/5%1%就显著）。那怎么让系数显著呢？

* 一是系数不要太小，但系数大小“可遇不可调”；
* 二是不要让标准误太大。

那么如何让标准误不要太大呢，我们推导一下标准误如何计算。



#### 3.对线性回归模型系数标准差标准误的理解

##### （1）生成数据

| y    | x    | e     |
| ---- | ---- | ----- |
| 3.6  | 1    | 0.63  |
| 3.4  | 2    | -1.38 |
| 7.6  | 3    | 1.01  |
| 7.4  | 4    | -1.01 |
| 11.6 | 5    | 1.38  |
| 11.4 | 6    | -0.63 |

![fig1](https://mengke25.github.io/images/memo20240525/fig1.png)

##### （2）回归

$$
y = \beta_{0}+\beta_{1}x+\epsilon
$$

$$
y_{i}=\beta_{0}+\beta_{1} x_{i}+e_{i}
$$

```stata
reg y x

      Source |       SS           df       MS      Number of obs   =         6
-------------+----------------------------------   F(1, 4)         =     34.60
       Model |   57.422285         1   57.422285   Prob > F        =    0.0042
    Residual |  6.63771505         4  1.65942876   R-squared       =    0.8964
-------------+----------------------------------   Adj R-squared   =    0.8705
       Total |  64.0600001         5      12.812   Root MSE        =    1.2882

------------------------------------------------------------------------------
           y | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
           x |   1.811429   .3079359     5.88   0.004     .9564615    2.666396
       _cons |       1.16   1.199238     0.97   0.388    -2.169618    4.489618
------------------------------------------------------------------------------

```



##### （3）计算回归的标准误差

###### a.SSE\SSR\SST

$SSE$: Sum of Squares Error,
$$
SSE= \sum_{i=1}^{n}(\hat{y_{i}}-y_{i})^2 = \sum_{i=1}^{n}(e_{i}-\bar{e})^2
$$
在本示例中，SSE=(3.6-2.97)^2+(3.4-4.78)^2+(7.6-6.95)^2+(7.4-8.41)^2+(11.6-10.22)^2+(11.4-12.03)^2 = 6.637713

$SSR$: Sum of Squares of the Regression
$$
SSR= \sum_{i=1}^{n}(\hat{y_{i}}-\bar{y})^2
$$

$SST$: Total Sum of Squares
$$
SST= \sum_{i=1}^{n}(y_{i}-\bar{y})^2
$$

###### b.MSE

回归的标准误差为：
$$
s^{2}=MSE=\frac{SSE}{n-K}=\frac{\sum_{i=1}^{n}(e_{i}-\bar{e})^2}{n-K}
$$

$$
s=\sqrt{MSE}
$$

$$
s^2 = \frac{6.637713}{6 - 2}=1.6594282; \ \ \ \ \ \ \   s=1.288188
$$

###### c.SE
$$
S_{\hat{\beta}} = \sqrt{\frac{s^2}{{\sum_{i=1}^{n}(x_{i}-\bar{x})}}}
$$

$$
S_{\hat{\beta}} = \sqrt{\frac{\frac{1}{n-2}\sum_{i=1}^{n} \hat{e^{2}}}{{\sum_{i=1}^{n}(x_{i}-\bar{x})}}}
$$

$$
S_{\hat{\beta}} = \sqrt{\frac{\frac{1}{4} \times 6.637713}{(1-3.5)^2+(2-3.5)^2+(3-3.5)^2+(4-3.5)^2+(5-3.5)^2+(6-3.5)^2}}
$$



标准误为何会很大？

* 样本少
* 极端值多
* X没有足够的variation



#### 4.结论

因此为了让回归结果显著，可以：

* `样本量不要太少`，因为较大的样本量有助于提高统计检验的功效，减少估计结果的随机误差。
* 查看变量分布，对`极端值进行截尾`（truncation）或`缩尾`（winsorization）处理，以减少异常值对回归结果的影响。截尾是指将超过一定阈值的极端值直接删除，而缩尾则是将极端值替换为接近阈值的数值。
* `保证变量具有足够的变差`，规避变量变差（variation）很小或几乎不变的情况。变量的变差过小会导致模型难以识别变量之间的关系，从而影响回归结果的显著性。









____

#### Appendix
##### 1. simulation code
```stata
clear 
set obs 6
gen y = 3.6 in 1 
replace y = 3.4 in 2 
replace y = 7.6 in 3
replace y = 7.4 in 4
replace y = 11.6 in 5
replace y = 11.4 in 6
gen x = _n

reg y x
predict xb

gen e = y - xb
format %9.2f xb 
format %9.2f e 
egen addtext_mean = rowmean(y xb)
forv i = 1/6{
	su add in `i',d
	global y`i' = r(mean)
	su e in `i',d
	global e`i' = r(mean)
}

tw (scatter y x, mlab(y) mlabp(1)) /// 
   (lfit y x) /// 
   (scatter xb x, mlab(xb) mlabp(1)) /// 
   (rspike y xb x) ,legend(off) /// 
   text($y1 0.9 "0.63",size(vsmall) color(red)) /// 
   text($y2 1.9 "-1.38",size(vsmall) color(red)) /// 
   text($y3 2.9 "1.01",size(vsmall) color(red)) /// 
   text($y4 3.9 "-1.01",size(vsmall) color(red)) /// 
   text($y5 4.9 "1.38",size(vsmall) color(red)) /// 
   text($y6 5.9 "-0.63",size(vsmall) color(red)) 
```



##### 2.序列相关 同方差 or 异方差
对于①参数线性②不存在“严格多重共线性”③随机抽样④严格外生性⑤“球形扰动项”(条件同方差+不存在自相关)五个假定均能够满足时

OLS估计量为BLUE，最优无偏线性估计量

此时，x的协方差矩阵为：
$$
Var(\hat{\beta_{1}}|x)=Var({\beta_{1}+\frac{\sum(x_{i}-\bar{x})e_{i}}{\sum(x_{i}-\bar{x})}}|x)
$$

$$
Var(\hat{\beta_{1}}|x)=\frac{Var(\sum(x_{i}-\bar{x})e_{i}|x)}{[\sum(x_{i}-\bar{x})^2]^2}
$$

* 倘若序列无关，那么和的方差即等价于方差的和，假设$Var(e_i|x)=\sigma^2$

$$
\sum(x_{i}-\bar{x})^2Var(e_i|x)
\left\{  
             \begin{array}{**lr**}  
             \sigma^2 \frac{\sum(x_i-\bar{x})}{[\sum(x_i-\bar{x})^2]^2}=\frac{\sigma^2}{\sum(x_i-\bar{x})^2}, & 同方差  \\  
             \frac{\sum(x_i-\bar{x})^2 \sigma_{i}^2}{\sum(x_i-\bar{x})^2}, & 异方差   
             \end{array}  
\right.
$$

* 序列相关：

$$
\hat{\sigma^2}=\frac{\sum e_{i}^2}{n-k-1}
$$

##### 3.calculate SE in matlab
```matlab
sqrt(inv(X'*X)*1.6594282)
```
